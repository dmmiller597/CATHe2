data:
  data_dir: "data"
  train_embeddings: "TED/s30/embeddings/prot_t5_embeddings_train.npz"
  val_embeddings: "TED/s30/embeddings/prot_t5_embeddings_val.npz"
  test_embeddings: "TED/s30/embeddings/prot_t5_embeddings_test.npz"
  train_labels: "TED/s30/embeddings/Y_Train_SF.csv"
  val_labels: "TED/s30/embeddings/Y_Val_SF.csv"
  test_labels: "TED/s30/embeddings/Y_Test_SF.csv"

model:
  # Architecture
  embedding_dim: 1024
  hidden_sizes: [1024, 1024, 1024]
  dropout: 0.3
  
  # Optimization
  learning_rate: 1e-3
  weight_decay: 1e-5

  # Learning rate scheduler
  lr_scheduler:
    monitor: "val/loss"
    mode: "min"
    factor: 0.5
    patience: 5
    min_lr: 1e-8

training:
  # Training parameters
  batch_size: 256
  max_epochs: 100
  accumulate_grad_batches: 4

  # Monitoring
  monitor_metric: "val/loss"
  monitor_mode: "min"
  early_stopping_patience: 5
  log_every_n_steps: 50
  
  # Hardware configuration
  num_workers: 2
  accelerator:
    float32_matmul_precision: "high"
    devices: 1
  
  # Training options
  seed: 42
  gradient_clip_val: 1.0
  precision: "16-mixed"

  # Output paths
  output_dir: "outputs"
  checkpoint_dir: "${training.output_dir}/checkpoints"
  log_dir: "${training.output_dir}/logs"
  