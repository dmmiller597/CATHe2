data:
  data_dir: "data"
  train_embeddings: "TED/prot_t5_embeddings_train.npz"
  val_embeddings: "TED/prot_t5_embeddings_val_filtered.npz"
  test_embeddings: "TED/prot_t5_embeddings_test_filtered.npz"
  train_labels: "TED/Y_Train_SF.csv"
  val_labels: "TED/Y_Val_SF_filtered.csv"
  test_labels: "TED/Y_Test_SF_filtered.csv"

model:
  # Architecture
  embedding_dim: 1024
  hidden_sizes: [1024, 1024, 1024]
  dropout: 0.3
  
  # Optimization
  learning_rate: 1e-4
  weight_decay: 1e-4

  # Learning rate scheduler
  lr_scheduler:
    monitor: "val/balanced_acc"
    mode: "max"
    factor: 0.5
    patience: 5
    min_lr: 1e-8

training:
  # Training parameters
  batch_size: 128
  max_epochs: 100
  accumulate_grad_batches: 8

  # Monitoring
  monitor_metric: "val/balanced_acc"
  monitor_mode: "max"
  early_stopping_patience: 5
  log_every_n_steps: 50
  
  # Hardware configuration
  num_workers: 2
  accelerator:
    float32_matmul_precision: "high"
    devices: 1
  
  # Training options
  seed: 42
  gradient_clip_val: 1.0
  precision: "16-mixed"
  
  # Memory optimization
  val_check_interval: 0.5
  limit_val_batches: 0.5

  # Output paths
  output_dir: "outputs"
  checkpoint_dir: "${training.output_dir}/checkpoints"
  log_dir: "${training.output_dir}/logs"
  