defaults:
  - _self_
  - data: protT5

data:
  train_sampling_strategy: "class_balanced" # "weighted" or "class_balanced"

model:
  # Architecture
  embedding_dim: ${data.embedding_dim}
  projection_dims: [1024]
  output_dim: 512
  dropout: 0.1
  loss_fn: "overlap" # "overlap" or "supcon"
  # Optimization
  learning_rate: 0.0001
  weight_decay: 0.1
  temperature: 0.07
  # --- Added Visualization ---
  visualization_method: "tsne" # "umap" or "tsne"
  enable_visualization: false
  tsne_viz_dir: "results/tsne_plots"
  umap_viz_dir: "results/umap_plots"
  evaluated_ids_output_dir: "results/evaluated_ids"
  min_class_size_for_eval: 2

training:
  # Training parameters
  batch_size: 128
  max_epochs: 100
  accumulate_grad_batches: 1

  # Monitoring
  monitor_metric: "val/loss"
  monitor_mode: "min"
  early_stopping_patience: 10
  log_every_n_steps: 100

  # Hardware configuration
  num_workers: 16
  accelerator:
    float32_matmul_precision: "high"
    devices: 1

  # Training options
  seed: 42
  gradient_clip_val: 0.1
  precision: "16-mixed"

  # Output paths - These will be dynamically modified per level
  output_dir: "outputs_contrastive" # Base output directory