data:
  data_dir: "data"
  train_embeddings: "embeddings/SF_Train_ProtT5.npz"
  val_embeddings: "embeddings/SF_Val_ProtT5.npz"
  test_embeddings: "embeddings/SF_Test_ProtT5.npz"
  train_labels: "annotations/Y_Train_SF.csv"
  val_labels: "annotations/Y_Val_SF.csv"
  test_labels: "annotations/Y_Test_SF.csv"

model:
  # Architecture - matching original 3x128 architecture with heavy regularization
  embedding_dim: 1024
  hidden_sizes: [128, 128, 128]
  dropout: 0.5
  use_leaky_relu: true
  leaky_relu_slope: 0.05
  
  # Optimization - matching original parameters
  learning_rate: 1e-5
  weight_decay: 1e-4  # Approximating the original's L2 regularization
  scheduler_factor: 0.1  # Original reduce factor
  scheduler_patience: 10  # Original patience
  focal_gamma: 0  # Disable focal loss to match original categorical crossentropy
  label_smoothing: 0  # Original doesn't use label smoothing

training:
  # Training parameters
  batch_size: 128  # Match original
  max_epochs: 200  # Match original
  early_stopping_patience: 30  # Match original
  accumulate_grad_batches: 1  # Original doesn't use gradient accumulation
  
  # Hardware configuration
  num_workers: 4
  accelerator:
    float32_matmul_precision: "high"
    devices: 1
  
  # Advanced training options
  seed: 42
  gradient_clip_val: 1.0
  precision: "32"  
  
  # Logging and checkpointing
  log_every_n_steps: 50
  monitor_metric: "val_accuracy" 
  monitor_mode: "max"
  
  # Output paths
  output_dir: "outputs"
  checkpoint_dir: "${training.output_dir}/checkpoints"
  log_dir: "${training.output_dir}/logs"